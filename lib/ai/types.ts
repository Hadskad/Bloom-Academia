/**
 * AI Agent Types
 *
 * TypeScript type definitions for the Multi-AI Agent system.
 * These types match the database schema defined in migration_001_multi_ai_system.sql
 *
 * Reference: Implementation_Roadmap_2.md - Section 1.2 Multi-AI Architecture
 */

/**
 * Agent role types - determines agent behavior
 */
export type AgentRole = 'coordinator' | 'subject' | 'support';

/**
 * Agent status - whether the agent is available for use
 */
export type AgentStatus = 'active' | 'maintenance' | 'disabled';

/**
 * Agent capabilities - what actions the agent can perform
 */
export interface AgentCapabilities {
  can_teach?: boolean;
  can_assess?: boolean;
  can_route?: boolean;
  can_motivate?: boolean;
  can_generate_svg?: boolean;
  can_grade?: boolean;
  can_validate?: boolean;
  specialties?: string[];
}

/**
 * Agent performance metrics - tracked over time
 */
export interface AgentPerformanceMetrics {
  total_interactions: number;
  avg_effectiveness: number;
  success_rate: number;
  last_updated?: string;
}

/**
 * AI Agent record from database
 * Matches the ai_agents table schema
 */
export interface AIAgent {
  id: string;
  name: string;
  role: AgentRole;
  model: string;
  system_prompt: string;
  subjects: string[];
  capabilities: AgentCapabilities;
  performance_metrics: AgentPerformanceMetrics;
  status: AgentStatus;
  created_at: string;
  updated_at: string;
}

/**
 * Routing decision from the Coordinator AI
 */
export interface RoutingDecision {
  route_to: string;       // Agent name or 'self'
  reason: string;         // Why this agent was chosen
  handoff_message?: string; // Optional message for smooth transition
  response?: string;      // Only if coordinator handles directly (route_to: 'self')
}

/**
 * Agent interaction record
 * Matches the agent_interactions table schema
 */
export interface AgentInteraction {
  id?: string;
  session_id: string;
  agent_id: string;
  user_message: string;
  agent_response: string;
  routing_reason?: string;
  handoff_from?: string;
  effectiveness_score?: number;
  response_time_ms?: number;
  timestamp?: string;
}

/**
 * Context passed to agents for generating responses
 */
export interface AgentContext {
  userId: string;
  sessionId: string;
  lessonId?: string;
  userProfile: {
    name: string;
    age: number;
    grade_level: number;
    learning_style?: string | null;
    strengths?: string[];
    struggles?: string[];
  };
  conversationHistory?: Array<{
    user_message: string;
    ai_response: string;
    timestamp?: string;
  }>;
  lessonContext?: {
    title: string;
    subject: string;
    learning_objective: string;
  };
  previousAgent?: string; // For handoff context
  // Audio input support (alternative to text userMessage)
  audioBase64?: string;  // Base64-encoded audio data
  audioMimeType?: string; // MIME type (e.g., 'audio/webm', 'audio/mp3')
  // Media input support (images and videos for vision analysis)
  mediaBase64?: string;   // Base64-encoded image or video data
  mediaMimeType?: string; // MIME type (e.g., 'image/jpeg', 'video/mp4')
  mediaType?: 'image' | 'video'; // Type of media uploaded
  // Adaptive teaching directives (Criterion 2: AI Adapts)
  // Generated by adaptive-directives.ts and injected into agent prompts
  adaptiveInstructions?: string; // Formatted directives text for prompt injection
}

/**
 * Google Search grounding source citation
 * Extracted from grounding metadata when Google Search is used
 *
 * Reference: https://ai.google.dev/gemini-api/docs/google-search
 */
export interface GroundingSource {
  title: string;    // Title of the web page
  url: string;      // URL of the source
  snippet?: string; // Optional snippet/rendered content
}

/**
 * Grounding metadata from Google Search
 * Available when Google Search tool is enabled for an agent
 *
 * Reference: https://ai.google.dev/gemini-api/docs/google-search
 */
export interface GroundingMetadata {
  webSearchQueries?: string[];  // Search queries generated by the model
  groundingChunks?: Array<{     // Grounding chunks with source information
    web?: {
      uri: string;    // URL of the source
      title?: string; // Title of the source
    };
  }>;
  sources?: GroundingSource[];  // Parsed sources for display
}

/**
 * Response from a specialist agent
 */
export interface AgentResponse {
  audioText: string;      // Text for TTS
  displayText: string;    // Text for screen display
  svg?: string | null;    // Optional SVG diagram
  lessonComplete?: boolean;
  agentName: string;      // Which agent responded
  agentId: string;        // DB id of the responding agent (avoids a re-fetch for interaction logging)
  handoffMessage?: string; // Message shown during agent transition
  handoffRequest?: string; // Request handoff to specific agent (e.g., 'motivator', 'assessor')
  teachingPhase?: number;  // 1-5: current teaching progression phase (1=Hook, 2=Instruction, 3=Guided, 4=Independent, 5=Consolidation)
  groundingMetadata?: GroundingMetadata; // Google Search grounding data (if applicable)
}

/**
 * Available agent names (for type safety)
 */
export type AgentName =
  | 'coordinator'
  | 'math_specialist'
  | 'science_specialist'
  | 'english_specialist'
  | 'history_specialist'
  | 'art_specialist'
  | 'assessor'
  | 'motivator'
  | 'validator';

/**
 * Progressive streaming response with early audioText extraction.
 * Used for Tier 2 latency optimization where TTS starts before
 * the complete LLM response is available.
 *
 * Reference: https://cresta.com/blog/engineering-for-real-time-voice-agent-latency
 */
export interface ProgressiveAgentResponse extends AgentResponse {
  /** First sentence extracted early from stream (for immediate TTS) */
  firstSentence: string;
  /** Remaining audioText after first sentence */
  remainingAudioText: string | null;
  /** Whether progressive extraction was used */
  usedProgressiveExtraction: boolean;
  /** Audio buffer for firstSentence, generated mid-stream while Gemini was still running.
   *  Present only when usedProgressiveExtraction is true. */
  firstSentenceAudio: Buffer | null;
}

/**
 * Validation result from the Validator agent
 *
 * Used to verify specialist responses before delivery to students.
 * Checks for factual accuracy, curriculum alignment, and pedagogical soundness.
 */
export interface ValidationResult {
  /** Whether the response passed validation */
  approved: boolean;
  /** Confidence score (0.0-1.0). Threshold for approval: >= 0.80 */
  confidenceScore: number;
  /** List of issues found (empty if approved) */
  issues: string[];
  /** Specific fixes required if rejected (null if approved) */
  requiredFixes: string[] | null;
}

/**
 * Validation failure record - logged for teacher dashboard review
 * Matches the validation_failures table schema
 */
export interface ValidationFailure {
  id?: string;
  session_id: string;
  agent_id: string;
  specialist_name: string;
  original_response: {
    audioText: string;
    displayText: string;
    svg: string | null;
  };
  validation_result: ValidationResult;
  retry_count: number;
  final_action: 'approved_after_retry' | 'delivered_with_disclaimer' | 'failed_validation';
  created_at?: string;
}
