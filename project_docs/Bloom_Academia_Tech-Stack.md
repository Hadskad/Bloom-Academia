TECH STACK DOCUMENT
Bloom Academia - 30-Day MVP
Complete Technology Stack & Architecture
INTRODUCTION
This document outlines every technology, library, service, and tool we're using to build the Bloom Academia MVP in 30 days. Each choice has been made to maximize development speed while maintaining production quality for the hackathon demo and investor presentations.

Key Principles:
â€¢	Serverless architecture for zero DevOps overhead
â€¢	Modern, well-documented technologies with strong community support
â€¢	Gemini 3 as the core (hackathon requirement)
â€¢	Fast iteration and deployment
â€¢	Production-ready from day one
â€ƒ
1. COMPLETE STACK OVERVIEW
Layer	Technology	Purpose
FRONTEND		
Framework	Next.js 15	React framework with SSR/SSG
UI Library	React 18	Core UI library
Language	TypeScript	Type safety, better DX
Styling	Tailwind CSS	Utility-first CSS framework
Components	shadcn/ui	Pre-built accessible components
Animation	Framer Motion	Smooth animations & transitions
Canvas	Fabric.js / Konva	Whiteboard rendering & SVG
State Management	Zustand	Lightweight global state
BACKEND		
API Layer	Next.js API Routes	Serverless functions
Database	Supabase (PostgreSQL)	Managed database + auth
ORM/Client	Supabase JS Client	Database interactions
Real-time	WebSocket	Bidirectional voice streaming
AI / ML
AI Model	Gemini 3 Flash with native audio support	Core AI teaching engine (audio sent directly to Gemini)
Speech-To-Text	Gemini native audio	Base64-encoded audio sent directly to Gemini API (no separate STT service)
Text-To-Speech	Google Cloud TTS	High-quality voice synthesis (Neural2 voices, streaming audio generation)
Memory System	Custom 3 layer architecture	Personalized learning context (User Profile + Session Memory + Long-term Analysis)
SVG generation	Gemini 3 Flash	On-the-fly visual aids generated during teaching responses
INFRASTRUCTURE		
Hosting	Vercel	Deploy + CDN + serverless
Version Control	Git + GitHub	Code repository
Domain/DNS	Vercel Domains	Custom domain setup
DEV TOOLS		
Code Editor	VS Code / Cursor	IDE with AI assistance
Package Manager	pnpm / npm	Dependency management
Linting	ESLint + Prettier	Code quality & formatting
â€ƒ
2. FRONTEND TECHNOLOGIES
2.1 Next.js 15 (Core Framework)
Why Next.js:
â€¢	React framework with built-in backend capabilities (API routes)
â€¢	Server-side rendering (SSR) for fast initial loads
â€¢	Static site generation (SSG) for landing page performance
â€¢	Built-in routing (no react-router needed)
â€¢	Optimized production builds out of the box
â€¢	Perfect Vercel integration (same company)

What we use it for:
â€¢	Landing page (SSG for speed)
â€¢	Application shell and routing
â€¢	API routes for backend logic
â€¢	Image optimization
â€¢	Font optimization

Installation:
npx create-next-app@latest ai-school --typescript --tailwind --app

2.2 React 18
Why React:
â€¢	Component-based architecture (perfect for reusable UI)
â€¢	Huge ecosystem and community
â€¢	Hooks for state management
â€¢	Concurrent features for smooth UX

Key React features we use:
â€¢	useState, useEffect for component state
â€¢	useContext for global state (with Zustand)
â€¢	useRef for canvas and audio element references
â€¢	Custom hooks for reusable logic

2.3 TypeScript
Why TypeScript:
â€¢	Catch errors before runtime
â€¢	Better autocomplete in VS Code/Cursor
â€¢	Self-documenting code (types as documentation)
â€¢	Easier refactoring
â€¢	Industry standard for production apps

Configuration:
tsconfig.json comes pre-configured with Next.js

2.4 Tailwind CSS
Why Tailwind:
â€¢	Utility-first CSS = fast styling
â€¢	No CSS file management
â€¢	Built-in design system (colors, spacing, etc.)
â€¢	Responsive design made easy
â€¢	Tree-shaking = minimal production CSS

Installation:
Comes with Next.js setup, configured automatically

Custom config (tailwind.config.js):
theme: {
  extend: {
    colors: {
      primary: '#4A90E2',
      secondary: '#7ED321',
      accent: '#F5A623'
    }
  }
}

2.5 shadcn/ui
Why shadcn/ui:
â€¢	Pre-built accessible components
â€¢	Built on Radix UI (accessibility primitives)
â€¢	Styled with Tailwind
â€¢	Copy-paste components (not a package dependency)
â€¢	Customizable source code

Components we'll use:
â€¢	Button
â€¢	Dialog/Modal
â€¢	Card
â€¢	Progress
â€¢	Dropdown Menu

Installation:
npx shadcn-ui@latest init
npx shadcn-ui@latest add button card progress
â€ƒ
2.6 Framer Motion
Why Framer Motion:
â€¢	Declarative animations for React
â€¢	Smooth, performant animations
â€¢	Easy gesture support
â€¢	Great documentation

What we use it for:
â€¢	Page transitions
â€¢	Whiteboard content animations (fade, slide)
â€¢	Voice indicator pulsing
â€¢	Celebration effects (confetti trigger)

Installation:
npm install framer-motion

Example usage:
import { motion } from 'framer-motion'
<motion.div initial={{opacity: 0}} animate={{opacity: 1}} />

2.7 Canvas Libraries (Fabric.js OR Konva)
Purpose: Interactive whiteboard rendering

Option 1: Fabric.js
â€¢	Powerful canvas library
â€¢	Great for SVG manipulation
â€¢	Good documentation
â€¢	Installation: npm install fabric

Option 2: Konva (with react-konva)
â€¢	React-first approach
â€¢	Declarative API
â€¢	Easier React integration
â€¢	Installation: npm install konva react-konva

Recommendation: Start with react-konva
Better React integration, easier to work with. Can switch to Fabric.js if needed.

What we'll render:
â€¢	SVG diagrams (pizzas, shapes, number lines)
â€¢	Mathematical equations
â€¢	Text with formatting
â€¢	Animated drawings

2.8 State Management (Zustand)
Why Zustand:
â€¢	Lightweight (< 1KB)
â€¢	Simpler than Redux
â€¢	TypeScript-friendly
â€¢	No boilerplate
â€¢	Perfect for small-to-medium apps

Installation:
npm install zustand

What we store:
â€¢	User profile (name, age, grade)
â€¢	Current lesson state
â€¢	Voice connection status
â€¢	Loading states
â€¢	Error messages

Example store:
import create from 'zustand'

const useStore = create((set) => ({
  userName: '',
  setUserName: (name) => set({ userName: name }),
  lessonProgress: 0,
  updateProgress: (progress) => set({ lessonProgress: progress })
}))
â€ƒ
3. BACKEND TECHNOLOGIES
3.1 Next.js API Routes (Serverless Backend)
What are API Routes:
â€¢	Server-side code that runs on Vercel's edge network
â€¢	Located in /app/api/ directory (Next.js 15 App Router)
â€¢	Each file = an API endpoint
â€¢	Automatically deployed with your frontend
Why this approach:
â€¢	No separate backend server to manage
â€¢	Auto-scaling (serverless)
â€¢	Same codebase as frontend
â€¢	TypeScript support
â€¢	Easy authentication
â€¢	Built-in Request/Response Web APIs
API Routes we'll create:
1. /api/teach (Main Teaching Endpoint)
â€¢	POST endpoint for complete teaching interaction
â€¢	Receives transcribed text from frontend
â€¢	Builds AI context from 3-layer memory system
â€¢	Calls Gemini 3 Flash for teaching response
â€¢	Generates audio via Google Cloud TTS
â€¢	Returns: text response, SVG code, audio base64
â€¢	Saves interaction to session memory
2. /api/stt/temp-key (Gemini native audio Authentication)
â€¢	GET endpoint to generate temporary Gemini native audio API key
â€¢	Keeps permanent API key secret from frontend
â€¢	Returns short-lived key for client-side WebSocket connection
â€¢	Expires in 60 seconds (renewable)
3. /api/tts/synthesize (Text-to-Speech)
â€¢	POST endpoint for audio generation
â€¢	Receives text, returns audio buffer
â€¢	Uses Google Cloud TTS Neural2 voices
â€¢	Handles streaming synthesis
4. /api/memory/profile (User Profile Management)
â€¢	GET: Fetch user learning profile from Supabase
â€¢	POST: Update user profile with discovered insights
â€¢	Returns: learning style, strengths, struggles, preferences
5. /api/memory/context (Context Builder)
â€¢	POST endpoint to build AI context
â€¢	Combines: user profile + session history + lesson data
â€¢	Returns: formatted system prompt for Gemini
6. /api/memory/analyze (Session Analysis)
â€¢	POST endpoint called after session ends
â€¢	Uses Gemini to analyze learning patterns
â€¢	Updates user profile with new insights
7. /api/progress/save (Progress Tracking)
â€¢	POST endpoint to save lesson progress
â€¢	Writes to Supabase: mastery level, time spent, completed status
8. /api/progress/load (Progress Loading)
â€¢	GET endpoint to load user progress
â€¢	Reads from Supabase, returns progress data
9. /api/lessons (Lesson Management)
â€¢	GET: List all available lessons
â€¢	Returns: lesson metadata, difficulty, subject
10. /api/lessons/[id] (Lesson Details)
â€¢	GET: Fetch specific lesson content
â€¢	Returns: full lesson structure and learning objectives
11. /api/sessions/start (Session Management)
â€¢	POST: Create new learning session in database
â€¢	Returns: session ID for tracking interactions
12. /api/sessions/end (Session Completion)
â€¢	POST: Mark session as ended
â€¢	Triggers learning analysis
â€¢	Updates user profile

3.2 Supabase (Database + BaaS)
What is Supabase:
â€¢	Open-source Firebase alternative
â€¢	PostgreSQL database (cloud-hosted)
â€¢	Built-in authentication
â€¢	Real-time subscriptions
â€¢	Auto-generated REST API
â€¢	Row-level security

Why Supabase:
â€¢	No database management (fully managed)
â€¢	Free tier is generous (500MB database, 2GB bandwidth)
â€¢	Easy to use JavaScript client
â€¢	Real-time features (for future use)
â€¢	Auth ready when we need it (post-MVP)

Setup:
1.	Sign up at supabase.com
2.	Create new project
3.	Get API keys (anon key + service role key)
4.	Install client: npm install @supabase/supabase-js

Database tables we'll create:
users:
â€¢	id, name, age, grade_level, learning_style, created_at
lessons:
â€¢	id, title, subject, description, grade_level
progress:
â€¢	id, user_id, lesson_id, mastery_level, time_spent, completed
sessions:
â€¢	id, user_id, lesson_id, started_at, ended_at, interaction_count

Client initialization:
// lib/supabase.ts
import { createClient } from '@supabase/supabase-js'

export const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
)

3.3 WebSocket (Real-time Communication)
Purpose:
â€¢	Bidirectional audio streaming with Gemini Live API
â€¢	Low-latency voice communication

Implementation:
â€¢	Native WebSocket API (browser built-in)
â€¢	Next.js API route acts as WebSocket proxy
â€¢	Connects frontend â†’ Next.js backend â†’ Gemini API

Why proxy through backend:
â€¢	Hide Gemini API key from frontend
â€¢	Add rate limiting if needed
â€¢	Log conversations for debugging
â€¢	Handle reconnection logic
â€ƒ
4. AI / ML TECHNOLOGIES (PRODUCTION IMPLEMENTATION)
4.1 Gemini 3 Flash - Multi-Agent Architecture
Model Details:
â€¢	Model name: gemini-3-flash-preview (Flash model for specialists)
â€¢	Validator uses: gemini-3-pro-preview (Pro model for validation)
â€¢	Released: January 2025
â€¢	Context window: 1 million tokens
â€¢	Input modalities: text, images, video, audio, PDFs
â€¢	Output modalities: text only (no native audio output)
â€¢	Advanced reasoning: Thinking levels (minimal, low, medium, high)
â€¢	Elo Score: 1501 (state-of-the-art reasoning)

Why Gemini 3 Flash + Multi-Agent System:
â€¢	Hackathon requirement (Gemini 3 hackathon) - âœ… Met
â€¢	Superior reasoning capability for complex teaching scenarios
â€¢	**9-agent system** with specialized roles and distinct thinking levels
â€¢	**Context caching** (75% cost reduction, 1-hour TTL)
â€¢	**Google Search grounding** for History/Science (factual accuracy + citations)
â€¢	**Validator agent** prevents hallucinations (regeneration loop with max 2 retries)
â€¢	1M token context window (maintains full conversation history)
â€¢	Can generate **structured JSON outputs** (Zod schema validation)
â€¢	Can generate **SVG code inline** for visual aids
â€¢	Excellent at explaining complex topics simply
â€¢	Cost-effective at Flash pricing tier

**Multi-Agent System Architecture:**
```typescript
// lib/ai/agent-manager.ts
export class AIAgentManager {
  // 9 agents with distinct thinking levels
  private getThinkingLevelForAgent(agentName: string): ThinkingLevel {
    // HIGH: math, english, history (complex reasoning)
    // MEDIUM: science, assessor (balanced)
    // LOW: coordinator, art, motivator (fast/intuitive)
  }

  // Validator with regeneration loop
  private async validateResponse(response, agent, context): Promise<ValidationResult> {
    // Uses Gemini 3 Pro with HIGH thinking
    // 5 validation categories: factual, curriculum, consistency, pedagogy, visual
    // Returns: approved (bool), confidenceScore (0-1), issues[], requiredFixes[]
  }
}
```

**New Libraries Added:**
- `@google/genai` v1.35.0+ (with ThinkingLevel enum support)
- `zod` - Structured output validation
- Custom cache manager (lib/ai/cache-manager.ts) - Gemini context caching
- Custom adaptive directives (lib/ai/adaptive-directives.ts) - Learning style adaptation
API Access:
â€¢	Sign up at ai.google.dev
â€¢	Get API key from Google AI Studio
â€¢	Apply for hackathon credits (free tier available for Flash)
â€¢	Install SDK: npm install @google/genai
Pricing:
â€¢	Input: $0.50 per 1M tokens
â€¢	Output: $3.00 per 1M tokens
â€¢	Free tier available for gemini-3-flash-preview
â€¢	Estimated cost per 30-min lesson: ~$0.05-0.10

4.2 Gemini native audio (Speech-to-Text)
What is Gemini native audio:
â€¢	Real-time speech recognition via WebSocket
â€¢	Ultra-low latency transcription (~100-300ms)
â€¢	60+ languages supported
â€¢	Speaker diarization and endpoint detection
â€¢	Browser-native integration (no server proxying needed)
Key Features:
â€¢	Endpoint detection: Knows when user stops speaking
â€¢	Interim results: Real-time word-by-word transcription
â€¢	High accuracy: Trained on diverse accents and backgrounds
â€¢	Language identification: Auto-detect spoken language
â€¢	Context customization: Improve accuracy with domain-specific terms
API Access:
â€¢	Sign up at soniox.com
â€¢	Get API key
â€¢	Generate temporary keys for client-side usage (60-second expiry)
â€¢	Install SDK: npm install @soniox/speech-to-text-web
Pricing:
â€¢	Real-time API: Contact for pricing
â€¢	Typical cost: ~$0.005-0.01 per minute
â€¢	Estimated cost per 30-min lesson: ~$0.15-0.30

4.3 Web Audio API (Browser Audio)
What is Web Audio API:
â€¢	Browser built-in API for audio processing
â€¢	No installation needed
â€¢	Captures microphone input
â€¢	Plays audio output

What we use it for:
â€¢	Request microphone permission
â€¢	Capture student's voice
â€¢	Convert to audio chunks for streaming
â€¢	Play AI's voice responses
â€¢	Show audio visualization (voice indicator)

Key APIs:
â€¢	navigator.mediaDevices.getUserMedia() - get mic access
â€¢	AudioContext - audio processing
â€¢	MediaRecorder - record audio chunks
â€¢	Audio element - play responses

Browser support:
â€¢	Chrome/Edge: Full support
â€¢	Safari: Full support (requires user gesture)
â€¢	Firefox: Full support
â€ƒ
5. INFRASTRUCTURE & DEPLOYMENT
5.1 Vercel (Hosting & Deployment)
What is Vercel:
â€¢	Serverless hosting platform
â€¢	Made by the creators of Next.js
â€¢	Global CDN for fast content delivery
â€¢	Automatic deployments from GitHub
â€¢	Built-in preview deployments

Why Vercel:
â€¢	Perfect Next.js integration
â€¢	Zero-config deployments
â€¢	Automatic HTTPS
â€¢	Edge functions (serverless API routes)
â€¢	Free tier is generous (100GB bandwidth)
â€¢	Custom domains included

Deployment workflow:
5.	Push code to GitHub main branch
6.	Vercel automatically detects changes
7.	Builds and deploys in ~2 minutes
8.	Live at your-app.vercel.app
9.	Every PR gets a preview URL

Setup:
10.	Sign up at vercel.com
11.	Connect GitHub repository
12.	Import Next.js project
13.	Add environment variables (API keys)
14.	Deploy!

Environment variables to set:
â€¢	GEMINI_API_KEY
â€¢	NEXT_PUBLIC_SUPABASE_URL
â€¢	NEXT_PUBLIC_SUPABASE_ANON_KEY
â€¢	SUPABASE_SERVICE_ROLE_KEY

5.2 Git + GitHub (Version Control)
Repository structure:
ai-school/
â”œâ”€â”€ app/                 # Next.js app directory
â”‚   â”œâ”€â”€ api/            # API routes
â”‚   â”œâ”€â”€ (routes)/       # Page routes
â”‚   â””â”€â”€ layout.tsx      # Root layout
â”œâ”€â”€ components/         # React components
â”œâ”€â”€ lib/                # Utilities, helpers
â”œâ”€â”€ public/             # Static assets
â”œâ”€â”€ styles/             # Global styles
â””â”€â”€ package.json

Branch strategy:
â€¢	main - production branch (auto-deploys to Vercel)
â€¢	dev - development branch
â€¢	feature/* - feature branches

5.3 Domain & DNS
Domain options:
â€¢	Use Vercel's free subdomain: your-app.vercel.app
â€¢	Or: Buy custom domain (e.g., aischool.ai)

Custom domain setup (if buying):
15.	Buy domain (Namecheap, GoDaddy, etc.)
16.	Add domain in Vercel dashboard
17.	Update DNS records to point to Vercel
18.	Automatic HTTPS certificate
19.	Live in ~48 hours
â€ƒ
6. DEVELOPMENT TOOLS
6.1 Code Editor
Recommended: VS Code or Cursor

VS Code Extensions:
â€¢	ES7+ React/Redux/React-Native snippets
â€¢	Tailwind CSS IntelliSense
â€¢	Prettier - Code formatter
â€¢	ESLint
â€¢	GitHub Copilot (AI coding assistant)

Cursor (Alternative):
â€¢	AI-first code editor (built on VS Code)
â€¢	Better AI assistance than Copilot
â€¢	Great for vibe coding
â€¢	Free tier available

6.2 Package Manager
Options:
â€¢	npm (comes with Node.js) - default
â€¢	pnpm (faster, saves disk space) - recommended
â€¢	yarn (alternative)

Recommendation: Use pnpm
Install: npm install -g pnpm
Usage: pnpm install, pnpm dev, pnpm build

6.3 Code Quality
ESLint (Linting):
â€¢	Catches code errors
â€¢	Enforces code style
â€¢	Comes pre-configured with Next.js
â€¢	Run: npm run lint

Prettier (Formatting):
â€¢	Auto-formats code
â€¢	Consistent style across team
â€¢	Install: npm install -D prettier
â€¢	Run: npx prettier --write .

.prettierrc config:
{
  "semi": true,
  "singleQuote": true,
  "tabWidth": 2,
  "trailingComma": "es5"
}
â€ƒ
7. OPTIONAL / NICE-TO-HAVE LIBRARIES
These aren't essential for MVP but can speed up development:

7.1 UI Utilities
clsx / classnames:
â€¢	Conditional className composition
â€¢	Install: npm install clsx
â€¢	Usage: clsx('btn', { 'btn-primary': isPrimary })

lucide-react (Icons):
â€¢	Clean, consistent icon set
â€¢	Tree-shakeable
â€¢	Install: npm install lucide-react
â€¢	Usage: import { Mic, Play, Pause } from 'lucide-react'

7.2 Development Utilities
react-hot-toast (Notifications):
â€¢	Toast notifications for success/error messages
â€¢	Install: npm install react-hot-toast

react-use (Hook collection):
â€¢	Useful React hooks
â€¢	Install: npm install react-use
â€¢	Includes: useLocalStorage, useDebounce, etc.

7.3 Analytics (Optional)
Vercel Analytics:
â€¢	Free with Vercel hosting
â€¢	Track page views, performance
â€¢	Install: npm install @vercel/analytics

PostHog (Product analytics):
â€¢	Track user behavior
â€¢	Feature flags
â€¢	A/B testing
â€¢	Free tier available
â€ƒ
8. ENVIRONMENT SETUP CHECKLIST
8.1 Prerequisites
â€¢	Node.js 18+ installed (download from nodejs.org)
â€¢	Git installed
â€¢	GitHub account created
â€¢	VS Code or Cursor installed

8.2 Service Accounts
Create accounts for:
20.	Vercel (vercel.com)
21.	Supabase (supabase.com)
22.	Google AI Studio (ai.google.dev) - for Gemini API key
23.	GitHub (github.com)

8.3 API Keys to Get
24.	Gemini API key from ai.google.dev
25.	Supabase URL + Anon Key from project settings
26.	Supabase Service Role Key (for backend)

8.4 Project Initialization
Step-by-step setup:
1. Create Next.js project:
   npx create-next-app@latest ai-school --typescript --tailwind --app

2. Install dependencies:
   cd ai-school
   pnpm install framer-motion zustand @supabase/supabase-js
   pnpm install react-konva konva
   pnpm install @google/generative-ai

3. Install shadcn/ui:
   npx shadcn-ui@latest init
   npx shadcn-ui@latest add button card progress dialog

4. Create .env.local file:
   GEMINI_API_KEY=your_key_here
   NEXT_PUBLIC_SUPABASE_URL=your_url
   NEXT_PUBLIC_SUPABASE_ANON_KEY=your_key

5. Initialize Git:
   git init
   git add .
   git commit -m "Initial commit"

6. Push to GitHub:
   Create repo on GitHub
   git remote add origin <your-repo-url>
   git push -u origin main

7. Deploy to Vercel:
   Connect GitHub repo in Vercel dashboard
   Add environment variables
   Deploy!
â€ƒ
9. QUICK REFERENCE SUMMARY (FINAL PRODUCTION STACK)
Core Stack (Implemented & Deployed)
â€¢	**Next.js 15** + React 18 + TypeScript âœ…
â€¢	**Tailwind CSS** + shadcn/ui (cva, Radix UI) âœ…
â€¢	**Framer Motion** (animations) âœ…
â€¢	**SVG rendering** (no canvas library - simplified) âœ…
â€¢	**Next.js API Routes** (serverless backend) âœ…
â€¢	**Supabase** (PostgreSQL + Auth) âœ…
â€¢	**Gemini 3 Flash** (gemini-3-flash-preview) âœ…
â€¢	**@google/genai** SDK v1.35.0+ (with ThinkingLevel) âœ…
â€¢	**Gemini native audio** (@soniox/speech-to-text-web) âœ…
â€¢	**Google Cloud TTS** Neural2 Streaming âœ…
â€¢	**Web Audio API** (voice capture/playback) âœ…
â€¢	**Vercel** (hosting + auto-deploy) âœ…

Advanced Features (Production)
â€¢	**Multi-Agent System** (9 agents in agent-manager.ts) âœ…
â€¢	**Context Caching** (cache-manager.ts, 75% cost reduction) âœ…
â€¢	**Adaptive Directives** (adaptive-directives.ts, 7 learning styles) âœ…
â€¢	**Mastery Detection** (mastery-detector.ts, 6 rules-based criteria) âœ…
â€¢	**Profile Enrichment** (profile-enricher.ts, real-time updates) âœ…
â€¢	**Trajectory Analysis** (trajectory-analyzer.ts, trend detection) âœ…
â€¢	**Evidence Extraction** (evidence-extractor.ts, learning analytics) âœ…
â€¢	**Validator Agent** (hallucination prevention with regeneration) âœ…
â€¢	**Google Search Grounding** (History/Science specialists only) âœ…
â€¢	**Zod Schema Validation** (structured JSON outputs) âœ…

Database Schema (Complete)
â€¢	`users` - Profiles with real-time enrichment âœ…
â€¢	`sessions` - Learning session tracking âœ…
â€¢	`interactions` - Conversation history âœ…
â€¢	`lessons` - Curriculum metadata âœ…
â€¢	`progress` - Per-lesson mastery tracking âœ…
â€¢	`mastery_evidence` - Learning analytics data âœ…
â€¢	`trajectory_snapshots` - Historical performance trends âœ…
â€¢	`validation_failures` - Quality assurance logs âœ…
â€¢	`ai_agents` - Multi-agent configuration âœ…

Development Commands
pnpm install          # Install dependencies
pnpm dev              # Start dev server (localhost:3000)
pnpm build            # Build for production
pnpm start            # Start production server
pnpm lint             # Run ESLint
git push              # Deploy to Vercel (auto)

Key File Locations
app/page.tsx          # Landing page
app/learn/page.tsx    # Learning interface
app/api/gemini/       # Gemini API routes
components/           # Reusable components
lib/supabase.ts       # Supabase client
lib/store.ts          # Zustand store
.env.local            # Environment variables

Important Links
â€¢	Next.js docs: nextjs.org/docs
â€¢	Tailwind docs: tailwindcss.com/docs
â€¢	shadcn/ui: ui.shadcn.com
â€¢	Gemini API: ai.google.dev/docs
â€¢	Supabase docs: supabase.com/docs
â€¢	Vercel docs: vercel.com/docs

Ready to build! In Sha Allah ðŸš€
* * * END OF TECH STACK DOCUMENT * * *
